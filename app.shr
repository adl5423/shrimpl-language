# app.shr
#
# Shrimpl 0.5.5 demo:
# - Data, ML, config, HTTP, and OpenAI helpers
# - Config-driven server (port/tls) via config/config.<env>.json
# - Built-in JWT auth (via config.auth.*)
# - Input validation + sanitization (via config.validation.schemas)
# - Structured JSON logging for each HTTP request
# - Basic ORM layer via `model` declarations + SQLite (shrimpl.db)
# - Rate limiting via @rate_limit(max, window_secs)
# - Built-in tests (`test "name": ... assert ...`)
#
# Open /__shrimpl/ui for the visual API UI.
#
# NOTE:
# - Recommended: set env var SHRIMPL_OPENAI_API_KEY before running
#     export SHRIMPL_OPENAI_API_KEY=sk-...
# - For quick testing in the UI, you can call:
#     GET /ai/set-key?key=sk-...

server 3000

# --- Models (ORM demo) -------------------------------------------------
#
# These `model` declarations are consumed by the Rust ORM layer at
# startup (init_global_orm) to auto-create tables in `shrimpl.db`.
#
# Example resulting schema (SQLite):
#   CREATE TABLE IF NOT EXISTS users (...);
#   CREATE TABLE IF NOT EXISTS tasks (...);
#
# You can exercise them via the /orm/* endpoints further below.

model User:
  id: int pk
  email: string
  name: string
  age?: int

model Task:
  id: int pk
  title: string
  status: string
  # Optional JSON payload as text
  payload?: string

# --- Functions ---------------------------------------------------------

func greet(name): "Hello " + name

# Numeric summary from three values (must be single-line expression)
func stats_summary(a, b, c): "sum=" + sum(number(a), number(b), number(c)) + ", avg=" + avg(number(a), number(b), number(c)) + ", min=" + min(number(a), number(b), number(c)) + ", max=" + max(number(a), number(b), number(c))

# --- OpenAI wrapper helpers -------------------------------------------

func set_openai_api_key(key): openai_set_api_key(key)
func set_openai_system(prompt): openai_set_system_prompt(prompt)
func chat_with_openai(prompt): openai_chat(prompt)
func chat_with_openai_json(prompt): openai_chat_json(prompt)
func call_openai_mcp(server_id, tool_name, args_json): openai_mcp_call(server_id, tool_name, args_json)

# --- New generic config + env helpers ---------------------------------

# Store a config key/value in the in-memory app config.
# Example:
#   /config/set?key=mode&value=demo
func config_set_value(key, value): config_set(key, value)

# Get a config value, or empty string if missing.
# Example:
#   /config/get?key=mode
func config_get_value(key): config_get(key)

# Get a config value with default.
# Example:
#   /config/get-or?key=mode&default=prod
func config_get_or_default(key, default): config_get(key, default)

# Check if a config key exists.
# Example:
#   /config/has?key=mode
func config_has_key(key): config_has(key)

# Read a single environment variable.
# Example:
#   /env?name=PATH
func read_env(name): env(name)

# --- HTTP client helpers ----------------------------------------------

# Simple pass-through demo that fetches raw text from a URL.
# Example:
#   /http/get?url=https://example.com
func http_proxy_get(url): http_get(url)

# Fetch JSON from a URL and pretty-print it.
# Example:
#   /http/get-json?url=https://api.github.com
func http_proxy_get_json(url): http_get_json(url)

# --- New control-flow / boolean / repeat helpers ----------------------

# 1) Age classification using if / elif / else and numeric comparisons.
#    Example:
#      /age-category?age=10  -> "child"
#      /age-category?age=15  -> "teen"
#      /age-category?age=30  -> "adult"
func classify_age(age): if number(age) < 13: "child" elif number(age) < 18: "teen" else: "adult"

# 2) Boolean + logical operators:
#    - number(age) >= 18
#    - upper(country) == "US"
#    - and / or
#
#    Examples:
#      /adult-us?age=20&country=US  -> "adult-us"
#      /adult-us?age=20&country=ca  -> "adult-non-us"
#      /adult-us?age=16&country=US  -> "not-adult"
func describe_adult_us(age, country): if number(age) >= 18 and upper(country) == "US": "adult-us" elif number(age) >= 18: "adult-non-us" else: "not-adult"

# 3) Simple truthiness demo using booleans.
#    "yes" -> true, anything else -> false
#    Endpoint returns "true" or "false" as a string.
func flag_to_bool(flag): if flag == "yes": true else: false

# 4) repeat N times: loop expression demo.
#    Returns the last value of the body expression, but in this case we
#    build up a concatenated greeting by using string concatenation inside
#    the loop body.
#
#    Example:
#      /repeat-greet?name=Ana&n=3 -> "Hello Ana! Hello Ana! Hello Ana!"
func repeat_greet(name, n): repeat number(n) times: "Hello " + name + "! "

# --- ORM helper functions ----------------------------------------------
#
# These wrap the built-in orm_insert / orm_find_by_id, so endpoints
# can stay concise and we centralize the model names.

func orm_insert_user(body): orm_insert("User", body)
func orm_get_user(id): orm_find_by_id("User", id)

func orm_insert_task(body): orm_insert("Task", body)
func orm_get_task(id): orm_find_by_id("Task", id)

# --- Classes -----------------------------------------------------------

class Math:
  double(x): x * 2

# --- Basic endpoints ---------------------------------------------------

endpoint GET "/": "Welcome to Shrimpl! Visit /__shrimpl/ui for the API UI."

endpoint GET "/hello/:name": greet(name)

endpoint GET "/double/:n": Math.double(n)

# Use an if / else expression to make the welcome more robust:
# - If "name" is empty or missing, show a generic greeting.
# - Otherwise, shout the name and show the length.
#
# Examples:
#   /welcome?name=aisen  -> "Hi AISEN! Name length: 5"
#   /welcome             -> "Hi there! No name provided."
endpoint GET "/welcome": if name == "": "Hi there! No name provided." else: "Hi " + upper(name) + "! Name length: " + len(name)

# Updated to reflect Shrimpl 0.5.5
endpoint GET "/info": json { "lang": "Shrimpl", "version": "0.5.5", "ui": "/__shrimpl/ui" }

# Numeric analysis from query (?a=10&b=5&c=15)
endpoint GET "/stats": stats_summary(a, b, c)

# --- Vector / tensor demos --------------------------------------------

# Returns a JSON vector, e.g. [1,2,3,4,5]
endpoint GET "/vec": vec(1, 2, 3, 4, 5)

# Dot product example: /dot?ax=1&ay=2&bx=3&by=4
endpoint GET "/dot": tensor_dot(vec(number(ax), number(ay)), vec(number(bx), number(by)))

# Elementwise addition example:
#   /tensor-add?ax=1&ay=2&bx=3&by=4  -> "[4,6]"
endpoint GET "/tensor-add": tensor_add(vec(number(ax), number(ay)), vec(number(bx), number(by)))

# --- DataFrame (pandas-ish) -------------------------------------------

# Load a CSV from a URL into a DF JSON
# Example: /load-data?url=https://people.sc.fsu.edu/~jburkardt/data/csv/hw_200.csv
endpoint GET "/load-data": df_from_csv(url)

# Peek first 5 rows of a DF (JSON string passed as query "df")
# In practice you’d POST this; here it’s just a demo.
endpoint GET "/head": df_head(df, 5)

# Select columns from a DF: /select?df=...&columns=col1,col2
endpoint GET "/select": df_select(df, columns)

# --- Simple ML: linear regression -------------------------------------

# Train a tiny model from xs and ys (JSON arrays)
# Example: /train-linreg?xs=[1,2,3,4]&ys=[2,4,6,8]
endpoint GET "/train-linreg": linreg_fit(xs, ys)

# Predict with trained model
# Example: /predict-linreg?model={...}&x=10
endpoint GET "/predict-linreg": linreg_predict(model, number(x))

# --- OpenAI / AI tooling demos ----------------------------------------

# 0) Testing helper: set the OpenAI API key from a query parameter.
#    /ai/set-key?key=sk-...
endpoint GET "/ai/set-key": set_openai_api_key(key)

# 1) Set the system prompt used by openai_chat / openai_chat_json.
#    /ai/set-system?prompt=You+are+Shrimpl+assistant...
endpoint GET "/ai/set-system": set_openai_system(prompt)

# 2) Conversational endpoint that takes a user prompt as query:
#    /ai/chat?prompt=Tell+me+about+Shrimpl
endpoint GET "/ai/chat": chat_with_openai(prompt)

# 3) Same, but returns the full JSON response as pretty JSON string:
#    /ai/chat-json?prompt=Explain+vectors+for+kids
endpoint GET "/ai/chat-json": chat_with_openai_json(prompt)

# 4) Self-test endpoint: minimal call to check the bridge works.
#    /ai/test-simple
endpoint GET "/ai/test-simple": chat_with_openai("Say exactly: Shrimpl OpenAI bridge is working.")

# 5) MCP / tools-style call (advanced). You pass the MCP server id,
#    tool name, and arguments JSON as query parameters:
#
#    /ai/mcp-call?server_id=my-mcp&tool_name=myTool&args_json={"query":"hi"}
#
#    The concrete values depend on how your OpenAI MCP setup is defined.
endpoint GET "/ai/mcp-call": call_openai_mcp(server_id, tool_name, args_json)

# --- New endpoints to exercise control flow directly ------------------

# /age-category?age=...
endpoint GET "/age-category": classify_age(age)

# /adult-us?age=...&country=...
endpoint GET "/adult-us": describe_adult_us(age, country)

# /flag?flag=yes|no
endpoint GET "/flag": flag_to_bool(flag)

# /repeat-greet?name=...&n=...
endpoint GET "/repeat-greet": repeat_greet(name, n)

# --- Config + env test endpoints --------------------------------------

# Store: /config/set?key=mode&value=demo
endpoint GET "/config/set": config_set_value(key, value)

# Get: /config/get?key=mode
endpoint GET "/config/get": config_get_value(key)

# Get with default: /config/get-or?key=mode&default=prod
endpoint GET "/config/get-or": config_get_or_default(key, default)

# Has: /config/has?key=mode
endpoint GET "/config/has": config_has_key(key)

# Env: /env?name=PATH
endpoint GET "/env": read_env(name)

# --- HTTP client test endpoints ---------------------------------------

# Raw text fetch:
#   /http/get?url=https://example.com
endpoint GET "/http/get": http_proxy_get(url)

# JSON pretty-print fetch:
#   /http/get-json?url=https://api.github.com
endpoint GET "/http/get-json": http_proxy_get_json(url)

# --- Auth + JWT + validation demo endpoints ---------------------------
#
# These endpoints rely on:
# - config.auth.* for which paths require JWT.
# - config.validation.schemas.* for JSON Schema validation.
# - http.rs middleware, which:
#   - validates JWT and injects:
#       jwt_sub, jwt_scope, jwt_role
#   - validates + sanitizes JSON body into:
#       body   (string with sanitized JSON)

# Public, unprotected endpoint to verify that the server is up and
# that logging is working without any JWT:
#   GET /public/ping
endpoint GET "/public/ping": "public-ok"

# Protected profile endpoint:
# - Mark /secure as protected in config.auth.protected_paths.
# - When called with a valid Authorization: Bearer <token>,
#   http.rs will:
#     - verify JWT
#     - inject jwt_sub / jwt_role / jwt_scope
# - This endpoint just reflects those values.
#
# Example (with valid JWT):
#   GET /secure/profile
#   -> "profile for demo-user (role=admin, scope=api:read api:write)"
endpoint GET "/secure/profile": if jwt_sub == "": "profile: anonymous (no jwt_sub claim)" else: "profile for " + jwt_sub + " (role=" + jwt_role + ", scope=" + jwt_scope + ")"

# Simple role-based check on top of JWT:
# - Same protection as above via config.
# - Additionally, checks jwt_role == "admin".
#
# Example:
#   GET /secure/admin  (with role=admin) -> "admin access granted"
#   GET /secure/admin  (with role=user)  -> "admin access denied (role=user)"
endpoint GET "/secure/admin": if jwt_role == "admin": "admin access granted" else: "admin access denied (role=" + jwt_role + ")"

# Validated + sanitized JSON body demo:
#
# - Configure JSON Schema for path "/orders/create" in config.validation.schemas.
# - http.rs will:
#     - parse request body as JSON
#     - validate against schema
#     - sanitize (trim strings, recurse into arrays/objects)
#     - serialize back and inject as `body` string
# - This endpoint returns the sanitized JSON string directly.
#
# Example:
#   POST /orders/create
#   Content-Type: application/json
#   Body:
#     { "customer_id": " 123 ", "total": 10.5,
#       "items": [{ "sku": " ABC ", "qty": 2 }] }
#
#   If valid, you get back the same JSON but with strings trimmed.
#   If invalid, http.rs returns 400 before this code runs.
endpoint POST "/orders/create": body

# Same as above, but unvalidated:
# - No schema configured -> http.rs just passes the raw body.
# - Useful to compare behavior with /orders/create.
endpoint POST "/orders/raw": body

# --- Rate limiting demo endpoints (@rate_limit) ------------------------
#
# These endpoints exercise the @rate_limit attribute parsing and
# middleware behavior.

# Example 1 (with parentheses):
#   @rate_limit(5, 60)  -> at most 5 requests per 60 seconds per client.
#
# Try:
#   curl 'http://localhost:3000/limited/ping'
#   ...repeat more than 5 times within a minute from the same client.
#   The server should start returning HTTP 429 once the limit is hit.
@rate_limit(5, 60)
endpoint GET "/limited/ping": "limited-ok: up to 5 requests per minute from a single client"

# Example 2 (space-separated, no parentheses):
#   @rate_limit 3 10  -> at most 3 requests per 10 seconds.
#
# Uses the existing stats_summary() function so you can also verify
# normal endpoint behavior while the rate limiter is active.
#
# Example:
#   curl 'http://localhost:3000/limited/stats?a=1&b=2&c=3'
@rate_limit 3 10
endpoint GET "/limited/stats": stats_summary(a, b, c)

# --- ORM demo endpoints ------------------------------------------------
#
# These exercise:
# - `model` parsing and Program.models population
# - SQLite migrations in init_global_orm()
# - Runtime helpers wired to orm_insert / orm_find_by_id

# Create a new user.
#
# Example:
#   curl -X POST 'http://localhost:3000/orm/users' \
#     -H 'Content-Type: application/json' \
#     -d '{ "id": 1, "email": "aisen@example.com", "name": "Aisen", "age": 30 }'
#
# Returns the rowid / primary key as a string on success.
endpoint POST "/orm/users": orm_insert_user(body)

# Fetch a user by primary key (integer id).
#
# Example:
#   curl 'http://localhost:3000/orm/users/1'
#
# - Path param `id` is a string like "1", which is valid JSON for a
#   numeric scalar, so orm_find_by_id parses it directly.
# - Returns:
#     { "id": 1, "email": "...", "name": "...", "age": 30 }
#   or an empty string / 404 depending on interpreter behavior for None.
endpoint GET "/orm/users/:id": orm_get_user(id)

# Create a new task with arbitrary payload.
#
# Example:
#   curl -X POST 'http://localhost:3000/orm/tasks' \
#     -H 'Content-Type: application/json' \
#     -d '{ "id": 42, "title": "Demo task", "status": "pending", "payload": "{\"foo\":123}" }'
endpoint POST "/orm/tasks": orm_insert_task(body)

# Fetch a task by primary key.
endpoint GET "/orm/tasks/:id": orm_get_task(id)

# --- Built-in tests ----------------------------------------------------
#
# These exercise the expression engine, control flow, and a few
# representative helper functions. How they are run depends on the
# CLI integration; they are also visible to the LSP / docs pipeline.

# Sanity-check that greet() works and that the expression engine can
# compare strings correctly.
test "greet-basic":
  assert greet("Shrimpl") == "Hello Shrimpl"

# Validate the if / elif / else control-flow in classify_age().
test "age-classification":
  assert classify_age("10") == "child"
  assert classify_age("15") == "teen"
  assert classify_age("30") == "adult"

# Validate boolean logic + and/or in describe_adult_us().
test "adult-us-logic":
  assert describe_adult_us("20", "US") == "adult-us"
  assert describe_adult_us("20", "ca") == "adult-non-us"
  assert describe_adult_us("16", "US") == "not-adult"

# Validate repeat N times loop behavior.
test "repeat-greet-output":
  assert repeat_greet("Ana", 2) == "Hello Ana! Hello Ana! "

# Quick numeric sanity check for stats_summary().
test "stats-summary-basic":
  assert stats_summary(1, 2, 3) == "sum=6, avg=2, min=1, max=3"
